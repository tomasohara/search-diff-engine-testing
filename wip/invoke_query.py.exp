#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
InvokeQuery module for handling search query construction, browser setup and result extraction.
Designed to be used for testing search engines like Scrappycito.
"""
# Standard Modules
import re
import urllib.parse
from typing import List, Dict, Any, Optional, Set, Tuple

# Installed Modules
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options as ChromeOptions
from selenium.webdriver.firefox.options import Options as FirefoxOptions
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException

# Constants
SCRAPPYCITO_MAIN = "http://www.scrappycito.com:9330"
SCRAPPYCITO_ALT = "http://www.tomasohara.trade:9330"
FUNCTION_WORDS = {"at", "the", "in", "on", "of", "and", "or", "a", "an", "for", "to", "with", "by"}
PAGE_LOAD_TIMEOUT = 30
QUERY_WAIT_TIMEOUT = 60


class InvokeQuery:
    """Class for handling search query construction, browser setup and result extraction"""
    
    def __init__(self, 
                 use_chrome: bool = False,
                 headless: bool = True,
                 base_url: str = SCRAPPYCITO_MAIN,
                 page_load_timeout: int = PAGE_LOAD_TIMEOUT,
                 query_wait_timeout: int = QUERY_WAIT_TIMEOUT):
        """
        Initialize with browser configuration options and set up the WebDriver.
        
        Args:
            use_chrome: Whether to use Chrome instead of Firefox
            headless: Whether to run the browser in headless mode
            base_url: Base URL for the search engine
            page_load_timeout: Timeout in seconds for page loading
            query_wait_timeout: Timeout in seconds for query results to appear
        """
        self.base_url = base_url
        self.page_load_timeout = page_load_timeout
        self.query_wait_timeout = query_wait_timeout
        self.driver = self._setup_browser(use_chrome, headless)
        
    def _setup_browser(self, use_chrome: bool, headless: bool):
        """
        Set up and configure the browser.
        
        Args:
            use_chrome: Whether to use Chrome instead of Firefox
            headless: Whether to run the browser in headless mode
            
        Returns:
            WebDriver: Configured Selenium WebDriver instance
            
        Raises:
            WebDriverException: If browser initialization fails
        """
        try:
            if use_chrome:
                options = ChromeOptions()
                if headless:
                    options.add_argument("--headless=new")
                options.add_argument("--no-sandbox")
                options.add_argument("--disable-dev-shm-usage")
                options.add_argument("--disable-gpu")
                driver = webdriver.Chrome(options=options)
            else:
                options = FirefoxOptions()
                options.set_preference("marionette.debugging.clicktostart", False)
                options.set_preference("marionette", True)
                options.set_preference("browser.download.folderList", 2)
                options.set_preference("browser.download.manager.showWhenStarting", False)
                if headless:
                    options.add_argument("--headless")
                driver = webdriver.Firefox(options=options)
            
            # Set page load timeout
            driver.set_page_load_timeout(self.page_load_timeout)
            return driver
        except WebDriverException as e:
            raise WebDriverException(f"Failed to initialize WebDriver: {str(e)}")
        
    def create_url(self, query: str) -> str:
        """
        Create the search URL with the encoded query.
        
        Args:
            query: Search query string
            
        Returns:
            str: Full search URL with encoded query
        """
        encoded_query = urllib.parse.quote_plus(query)
        return f"{self.base_url}/run_search?query={encoded_query}&its-me=on"
        
    def extract_query_results(self, url: str, query_terms: str) -> Tuple[List[Dict[str, Any]], int, float, Optional[str]]:
        """
        Navigate to URL and extract search results with relevance checking.
        
        Args:
            url: Search URL to navigate to
            query_terms: Query terms to check for relevance
            
        Returns:
            Tuple containing:
                - List of result dictionaries
                - Count of relevant results
                - Relevance ratio
                - Result statistics text (if available)
        """
        try:
            try:
                self.driver.get(url)
            except TimeoutException:
                print(f"Page load timed out after {self.page_load_timeout}s, but continuing anyway")
            
            try:
                wait = WebDriverWait(self.driver, self.query_wait_timeout)
                wait.until(EC.presence_of_element_located((By.CLASS_NAME, "cell-text")))
            except TimeoutException:
                print(f"Timed out waiting for search results after {self.query_wait_timeout}s")
                return [], 0, 0, None
                
            # Extract result statistics
            result_stats = None
            try:
                stats_element = self.driver.find_element(By.CLASS_NAME, "result-stats")
                result_stats = stats_element.text
            except NoSuchElementException:
                print("No result statistics found")
            
            # Extract search results
            search_results = self.driver.find_elements(By.CLASS_NAME, "cell-text")
            result_list = []
            
            if len(search_results) < 3:
                print("Warning: Not enough search results found")
                return [], 0, 0, result_stats
                
            for i in range(0, len(search_results) - 2, 3):
                if i + 2 < len(search_results):
                    title = search_results[i].text
                    website = search_results[i + 1].text
                    snippet = search_results[i + 2].text
                    
                    result_list.append({
                        "title": title,
                        "website": website,
                        "snippet": snippet,
                        "query_terms": snippet.split("; ") if "; " in snippet else []
                    })
            
            # Remove last item if it exists (it's usually incomplete)
            if result_list and len(result_list) > 0:
                result_list.pop()
                
            # Calculate how many results contain query terms
            non_function_terms = self._get_non_function_words(query_terms)
            relevant_count = 0
            
            for result in result_list:
                if self._is_result_relevant(result, non_function_terms):
                    relevant_count += 1
            
            relevance_ratio = relevant_count / len(result_list) if result_list else 0
            
            return result_list, relevant_count, relevance_ratio, result_stats
            
        except Exception as e:
            print(f"Error extracting results: {str(e)}")
            return [], 0, 0, None
    
    def _get_non_function_words(self, query: str) -> Set[str]:
        """
        Extract non-function words from query.
        
        Args:
            query: Search query string
            
        Returns:
            Set of non-function words from the query
        """
        words = set(re.findall(r'\b\w+\b', query.lower()))
        return words - FUNCTION_WORDS
    
    def _is_result_relevant(self, result: Dict[str, Any], query_terms: Set[str]) -> bool:
        """
        Check if a result contains any of the query terms.
        
        Args:
            result: Result dictionary
            query_terms: Set of query terms to check for
            
        Returns:
            bool: True if result is relevant, False otherwise
        """
        combined_text = f"{result['title']} {result['snippet']}".lower()
        
        for term in query_terms:
            if term.lower() in combined_text:
                return True
        return False
            
    def run_query(self, query: str) -> Tuple[List[Dict[str, Any]], int, float, Optional[str]]:
        """
        Run a query and return results with relevance metrics.
        
        Args:
            query: Search query string
            
        Returns:
            Tuple containing:
                - List of result dictionaries
                - Count of relevant results
                - Relevance ratio
                - Result statistics text (if available)
        """
        url = self.create_url(query)
        results, relevant_count, relevance_ratio, stats = self.extract_query_results(url, query)
        return results, relevant_count, relevance_ratio, stats
        
    def close(self):
        """Close the browser and clean up resources"""
        if self.driver:
            try:
                self.driver.quit()
            except Exception as e:
                print(f"Error closing browser: {str(e)}")
    
    def __enter__(self):
        """Support for context manager protocol"""
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Support for context manager protocol"""
        self.close()